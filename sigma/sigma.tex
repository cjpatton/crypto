\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage[toc,page]{appendix}
\usepackage[font={small}]{caption}
\usepackage{amsthm}
\input{header}
\input{macros}

\def\dashuline{\bgroup
  \ifdim\ULdepth=\maxdimen  % Set depth based on font, if not set already
    \settodepth\ULdepth{(j}\advance\ULdepth.4pt\fi
  \markoverwith{\kern.15em
  \vtop{\kern\ULdepth \hrule width .3em}%
  \kern.15em}\ULon}

\newcounter{foot}
\setcounter{foot}{1}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}

\newtheorem{lemma}{Lemma}

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\setcounter{tocdepth}{2}

\title{\thetitle}
\author{Christopher Patton, cjpatton@ufl.edu}
\date{2018/4/16, CIS 5371, Spring 2019, University of Florida}

\begin{document}

\maketitle

\begin{abstract}
  \noindent
  An overview of the Schnorr signature scheme and its security. The widely-used
  EdDSA scheme is based on Schnorr, and the underlying theory is used to
  construct efficient \emph{zero-knowledge proof systems}, which have a ton of
  interesting applications (e.g., cryptocurrencies).
  %
  These notes are derived from Boneh-Shoup's book \emph{A Graduate Course in
  Applied Cryptography}, available on line at
  \url{https://crypto.stanford.edu/~dabo/cryptobook/}.
\end{abstract}

\section{The goal}

We're given cyclic group group~$\G$ generated by~$g$ and with prime order~$q$.
We will denote the group operation by multiplication.
%
We will assume that computing discrete logarithms in~$\G$ is hard; more
formally, the \dl advantage of any ``reasonable'' adversary~$\I$ is ``small'',
where the \dl advantage of~$\I$ is
%
\[
  \Adv{\dl}_\G(\I) \bydef
    \Prob{
      g^{s'} = g^{s} :
        s \getsr \Z_q; P \gets g^s; s' \getsr \I(P)
    }\,.
\]
%
Our goal is to construct a signature scheme who's security follows from the
presumed hardness of the \dl problem for~$\G$. In particular, given an adversary
that breaks the \ufcma security of our signature scheme, we will construct an
algorithm that breaks the \dl assumption for~$\G$.
%
Recall that a signature scheme is a triple $\Pi = (\gen,\sign,\verify)$:
\begin{itemize}
  \item $(\pk, \sk) \getsr \gen(\,)$ denotes execution of the key
    generator;%
    %
    \footnote{Note that we've dropped the security parameter from the syntax; in
    particular, the key generator takes no inputs instead of taking
    in~$\lambda$. This is OK! The security parameter is helpful when talking
    about certain kinds of signature schemes, e.g., those based on the \emph{RSA
    assumption}. (More on this later in the semester.) But we won't need it for
    the signature scheme we're discussing today.}
  \item $\sigma \getsr \sign(\sk, M)$ denotes execution of the signer; and
  \item $v \gets \verify(\pk, M, \sigma)$ denotes execution of the verifier.
\end{itemize}
%
Correctness requires that for all messages $M$, all key pairs
$(\pk,\sk)\in[\gen(\,)]$, and all signatures $\sigma\in[\sign(\sk,M)]$ it holds
that $\verify(\pk, M, \sigma)=1$.%
%
\footnote{The notation ``$[\A(x)]$'' denotes the set of all possible
outputs of~$\A$ when run on input~$x$.} %
%
\emph{Unforgeability under chosen message attack} is captured by the \ufcma
experiment in \fig{ufcma}. We define the advantage of a forger~$\F$ in
attacking~$\Pi$ as
%
\[
  \Adv{\ufcma}_{\Pi}(\F) \bydef 2\Prob{\Exp{\ufcma}_{\Pi}(\F)=1}-1 \,.
\]

\begin{figure}
  \threeColsNoDivideUnbalanced{0.40}{0.28}{0.28}
  {\ga
    \fu $\Exp{\ufcma}_{\Pi}(\F)$\\[2pt]
      \li $b \gets \bits$; $(\pk, \sk) \getsr \gen(\,)$\\
      \li $\Q \gets \emptyset$ \#{Used to exclude trivial attacks.}\\
      \li $b' \getsr \F^{\,\SIGNO,\VERIFYO}(\pk)$\\
      \li \rreturn $(b'=b')$
  }
  {
    \fu $\SIGNO(M)$\\[2pt]
      \li $\sigma \getsr \sign(\sk,M)$\\
      \li $\Q \gets \Q \union \{(M,\sigma)\}$\\
      \li \rreturn $\sigma$
  }
  {
    \fu $\VERIFYO(M,\sigma)$\\[2pt]
      \li \rif $(M,\sigma)\in\Q$ \rthen \rreturn $\bot$\\
      \li \rif $b=0$ \rthen \rreturn $0$\\
      \li \rreturn $\verify(\pk,M,\sigma)$
  }
  \caption{The \ufcma experiment for a signature scheme
  $\Pi=(\gen,\sign,\verify)$.}
  \label{fig:ufcma}
\end{figure}


\section{The scheme}

The Schnorr signature scheme is constructed from a very simple protocol called
\emph{Schnorr's identification protocol}. We will first see how this protocol works
what are its security properties. We will then see how to transform it into a
signature scheme that achieves \ufcma security.

\subsection{Schnorr's identification protocol}
\begin{figure}
  \centering
  \begin{tabular}{lcl}
    $\underline{\prover(s)}$ &  & $\underline{\verifier(P)}$  \\[2pt]

    $r \getsr \Z_q$; $R \gets g^r$ \\ \#{Commit} & $\sendright{R\in\G}$ \\

    && $h \getsr \Z_q$ \\ & $\sendleft{h\in\Z_q}$ & \#{Challenge} \\

    $x \gets r + sh$ \\ \#{Prove} & $\sendright{x\in\Z_q}$ \\

    && \rassert $g^x = R \cdot P^h$
  \end{tabular}
  \caption{Schnorr's identification protocol.}
  \label{fig:id}
\end{figure}

\noindent The protocol involves a \emph{prover} and a \emph{verifier}. Suppose
the prover knows a secret key $s\in\Z_q$ and the verifier knows the
corresponding public key $P=g^s\in\G$. The prover's goal is to convince the
verifier that it knows the secret key. Now, an obvious solution is to just
hand~$s$ to the verifier, but what we need to do is convince the verifier
without revealing any information about the secret key to the verifier. Consider
the 3-round protocol in \fig{id}:
\begin{enumerate}
  \item The prover generates and sends a \emph{commitment}~$R=g^r$.
  \item The verifier replies with a random \emph{challenge}~$h$.
  \item Finally, the prover computes a \emph{proof}~$x\equiv r+sh \pmod q$ and
    sends it to the verifier.
\end{enumerate}
%
The verifier checks that $g^x = R\cdot P^h$. If so, then it decides that the
prover knows the secret key; otherwise it decides the prover is cheating.
%
Why does this work? The protocol is guaranteed to succeed if the prover is
honest because
%
\begin{equation}
  g^x = g^{r + sh} = g^r \cdot g^{sh} = R \cdot (g^{s})^h = R \cdot P^h
  \,.
\end{equation}
%
But what if the prover is \emph{dishonest}? Is it possible for an attacker who
knows~$P$ but not~$s$ to fool the verifier into thinking it knows the secret key?

\subsubsection{A useful abstraction}

To answer this question, we must (as usual) first formalize what Schnorr's
protocol \emph{is}.
%
In general, an identification protocol is given by a key generator and a
specification of how the prover and verifier interact (cf. Boneh-Shoup,
Def.~18.1). Our 3-round protocol is one example. Another is password-based
authentication: The ``key generator'' (i.e., \underline{you!}) chooses a
password $\pw$ to be the secret ``key'' and computes the verification key as
$H(\pw)$. To login, you just compute the hash of your password and send it to
the server. (Note that this na\"ive protocol is
actually not very secure!)
\ignore{
\begin{figure}[h]
  \centering
  \begin{tabular}{lcl}
    $\underline{\prover(\pw)}$ &  & $\underline{\verifier(V)}$  \\[2pt]

    $U \gets H(\pw)$ & $\sendright{U}$ & \rassert $U = V$ \\
  \end{tabular}
  \caption{A na\"ive password-based identification protcol. The verification key
  is $V=H(\pw)$.}
  \label{fig:pw}
\end{figure}
}

It will be convenient for us to work with a more specialized syntax. A
\emph{commit-then-prove identification (ID) scheme} is a tuple of algorithms $\Sigma =
(\gen,\commit,\prove,\verify)$ with a finite \emph{challenge set~$\Y$}:
\begin{itemize}
  \item $(P,s)\getsr\gen(\,)$ denotes key generation;
  \item $(R,r)\getsr\commit(s)$ denotes commitment ($\prover(s)$, step 1);
  \item $h\getsr\Y$ denotes challenge generation ($\verifier(P)$, step 1);
  \item $x\getsr\prove(s,r,h)$ denotes proof generation ($\prover(s)$, step 2); and
  \item $v\gets\verify(P,R,h,x)$ denotes verification ($\verifier(P)$, step 2).
\end{itemize}
%
Correctness requires that for all $(P,s)\in[\gen(\,)]$, $(R,r)\in[\commit(s)]$,
$h\in\Y$, and $x\in[\prove(s,r,h)]$ it holds that
$\verify(P,R,h,x)=1$.
%
Note that the challenge is independent of all preceding choices made in the
protocol so far; this will be important later on.

Hopefully it's clear that we can express Schnorr's identification protocol as a
commit-then-prove ID scheme. Let's call it $\Schnorr$.

\begin{figure}
  \threeColsUnbalanced{0.30}{0.30}{0.36}
  {
    \fu $\Exp{\id1}_{\Sigma}(\A)$\\[2pt]
      \li $(P,s)\getsr\gen(\,)$\\
      \li $R, h, x \gets \bot$\\
      \li $\win \gets 0$\\\
      \li $\A^{\COMMIT1,\PROVE1}(P)$\\
      \li \rreturn $\win$
    \\[6pt]
    \fu $\COMMIT1(R')$\\[2pt]
      \li \rif $R\ne\bot$ \rthen \rreturn $\bot$\\
      \li $R \gets R'$\\
      \li $h \getsr \Y$\\
      \li \rreturn $h$
    \\[6pt]
    \fu $\PROVE1(x')$\\[2pt]
      \li \rif $x\ne\bot \bor R=\bot$ \rthen \rreturn $\bot$\\
      \li $x \gets x'$\\
      \li $v \gets \verify(P,R,h,x)$\\
      \li $\win \gets \win \bor v$\\
      \li \rreturn $v$
  }
  {
    \fu $\Exp{\id2}_{\Sigma}(\A)$\\[2pt]
      \li $(P,s)\getsr\gen(\,)$\\
      \li $R, h, x \gets \bot$\\
      \li $\win \gets 0$\\\
      \li $\A^{\COMMIT1,\PROVE1,\RUN}(P)$\\
      \li \rreturn $\win$
    \\[6pt]
    \fu $\RUN(\,)$\\[2pt]
      \li $(R',r') \getsr \commit(s)$\\
      \li $h' \getsr \Y$\\
      \li $x' \getsr \prove(s,r',h')$\\
      \li \rreturn $(R',h',x')$
  }
  {
    \fu $\Exp{r\id2}_{\Sigma,r}(\A)$\\[2pt]
      \li $(P,s)\getsr\gen(\,)$\\
      \li $R_1, \ldots, R_r, h_1, \ldots, h_r, x_1, \ldots, x_r \gets \bot$\\
      \li $\win \gets 0$\\\
      \li $\A^{\COMMIT{},\PROVE{},\RUN}(P)$\\
      \li \rreturn $\win$
    \\[6pt]
    \fu $\COMMIT{}(i,R')$\\[2pt]
      \li \rif $R_i\ne\bot$ \rthen \rreturn $\bot$\\
      \li $R_i \gets R'$\\
      \li $h_i \getsr \Y$\\
      \li \rreturn $h_i$
    \\[6pt]
    \fu $\PROVE{}(i,x')$\\[2pt]
      \li \rif $x_i\ne\bot \bor R_i=\bot$ \rthen \rreturn $\bot$\\
      \li $x_i \gets x'$\\
      \li $v \gets \verify(P,R_i,h_i,x_i)$\\
      \li $\win \gets \win \bor v$\\
      \li \rreturn $v$
  }
  \caption{Security games for \id1, \id2, and r\id2 for commit-then-prove
  ID scheme $\Sigma = (\gen,\commit,\prove,\verify)$ with challenge set~$\Y$.}
  \label{fig:id1}
  \label{fig:id2}
  \label{fig:rid2}
  \vspace{6pt}\hrule
\end{figure}

\subsubsection{\id1 security}
%
The first security property we will consider captures an adversary's advantage
in \emph{directly} impersonating the prover to the verifier.
%
The \id1 game in \fig{id1} codifies the adversary's behavior in the protocol.
First, the key generator is run and the adversary~$\A$ is handed the public key.
%
It then computes a commitment and sends it to the verifier by querying
its~$\COMMIT1$ oracle. The oracle responds by generating and returning a
challenge just as the verifier would.
%
To finish the game, the adversary computes a proof and passes it to its
$\PROVE1$ oracle. The game attempts to verify the proof using the public key,
the commitment, and the challenge; the adversary wins if and only if
verification succeeds. The game oracles and state are defined so that the
adversary only gets to attempt one impersonation.
%
Define the \id1 advantage of~$\A$ in impersonating the prover to the verifier
in ID scheme $\Sigma$ as
%
\[
  \Adv{\id1}_{\Sigma}(\A) \bydef
    \Prob{\Exp{\id1}_{\Sigma}(\A)=1} \,.
\]

We can prove that $\Schnorr$ is \id1 secure if the \dl problem is hard for the
group~$\G$. This is given by the following lemma.

\begin{lemma}\label{lemma:dl->id1}
  For every $t$-time \id1-adversary~$\A$ there exists a $O(t)$-time
  \dl-adversary~$\I$ such that
  \begin{equation}
    \Adv{\id1}_\Schnorr(\A) \leq 1/q + \sqrt{\Adv{\dl}_\G(\I)}
    \;.
  \end{equation}
\end{lemma}
\begin{proof}[Proof sketch.]
  The proof is somewhat technical, so we'll just sketch the most interesting
  ideas.
  %
  We're given $P\in\G$ (an instance of the \dl game) and our goal is to
  compute~$s$ such that $P=g^s$. We have at our disposal an algorithm~$\A$ that
  wins the \id1 game with high probability. We will use~$\A$ to
  \emph{extract}~$s$ from~$P$.
  %
  We will assume that~$\A$ behaves \emph{properly}, i.e., it queries each oracle
  exactly once and queries $\COMMIT1$ first. (Basically, $\A$ acts like a
  cheating prover.) This assumption is without loss of generality because we can
  easily transform any~$\A$ into a properly behaved adversary that gets at least
  as much advantage.
  %
  We can write the execution of~$\A^{\COMMIT1,\PROVE1}(P)$ in terms of a pair of
  algorithms $(\A',\A'')$ as follows:
  %
  \[
    (R, \sigma) \getsr \A'(P);
    h \getsr \COMMIT1(R);
    x \getsr \A''(h,\sigma);
    v \gets \PROVE1(x)
  \]
  %
  That is, the adversary runs in two stages: the first stage~$\A'$ computes the
  commitment, and the second stage~$\A''$ computes the proof.
  String~$\sigma\in\bits^*$ is an ``advice string'' used to pass state from
  the first stage to the second.

  Now we're ready to specify our \dl adversary~$\I$. On input of~$P$,
  algorithm~$\I$ does as follows.
  %
  It runs the first stage $(R, \sigma) \getsr \A'(P)$ then runs the second stage
  \emph{twice} as follows:
  %
  \[
    h_1 \getsr \Y;
    x_1 \getsr \A''(h_1,\sigma);
    h_2 \getsr \Y;
    x_2 \getsr \A''(h_2,\sigma)
  \]
  %
  In the process, our adversary~$\I$ has produced two protocol
  \emph{transcripts} $(R,h_1,x_1)$ and $(R,h_2,x_2)$ that share a commitment.
  We say they're both \emph{valid} if $\verify(P,R,h_1,x_1)=1$ and
  $\verify(P,R,h_2,x_2)=1$. Assuming they are, adversary~$\I$ can easily compute
  the secret key as follows.
  %
  By assumption we have that
  %
  \begin{equation}
    g^{x_1} = R \cdot P^{h_1} \;\text{and}\; g^{x_2} = R \cdot P^{h_2} \,.
  \end{equation}
  %
  Solving for~$R$ in the right equation and substituting it in the left yields
  \begin{equation}
    g^{x_1} = ({g^{x_2}}{P^{-h_2}})P^{h_1} \implies
    {g^{x_1-x_2}} = {P^{h_1-h_2}} \implies
      g^{x'} = P^{h'} \,,
  \end{equation} where $h' \equiv h_1 - h_2 \pmod q$ and $x' \equiv x_1 - x_2
  \pmod q$.
  %
  Since~$q$ is prime, if $h'\ne0$, then $h'$ has a unique multiplicative inverse
  $1/h' \pmod q$. It follows that $P = g^{x'/h'}$, which implies that $s =
  x'/h'$.

  That's the reduction. Simple enough! Two conditions must hold in order
  for~$\I$ to succeed. First, we require that $h_1-h_2\ne0$ holds. But
  $h_1-h_2=0$ holds with only negligible probability (in particular, $1/q$).
  %
  Second, both transcripts must be valid. Intuitively, if $\A$ succeeds with
  probability~$\delta$, then the probability that the \emph{first} transcript is
  valid is also~$\delta$; but what about the \emph{second}? The transcripts
  share the same commitment, so they're distributions are not independent.
  Carefully addressing these details takes some doing; check out Lemma 19.2 in
  Boneh-Franklin for the details.
\end{proof}

We've just seen how to efficiently extract the discrete log of an
element~$P\in\G$ using an algorithm that successfully impersonates the prover in
Schnorr's ID protocol.  This implies that~$\Schnorr$ is \id1 secure if the \dl
assumption holds for~$\G$.
%
That's pretty cool, but how useful is this result, really? The \id1 attack model
is rather weak: first, the adversary is only permitted one impersonation
attempt, whereas in practice, it may be able to mount \emph{many} attempts; and
second, the attacker may be able to eavesdrop on one or more executions of
the protocol between the verifier and the honest prover. We'll address both of
these attack vectors in the remainder.

\subsubsection{\id2 security}
Let's begin with the latter. The \id2 game in \fig{id2} is just like the \id1
game, except the adversary is given an additional oracle~$\RUN$. This oracle
takes no inputs and simply executes the protocol and returns the transcript to
the adversary. The advantage of an \id2-adversary~$\A$ in attacking a
commit-then-prove ID scheme~$\Sigma$, defined as
$\Adv{\id2}_{\Sigma}(\A)=\Prob{\Exp{\id2}_{\Sigma}(\A)}$, measures $\A$'s
ability to impersonate the prover when it may eavesdrop in this manner.

Can an attacker exploit this additional information to weaken or
break~$\Schnorr$? The answer might surprise you. The following lemma says that
breaking~$\Schnorr$ in the sense of \id2 security is no easier than breaking it
in the sense of \id1.  In other words, eavesdropping doesn't help at all!

\begin{lemma}\label{lemma:id1->id2}
  For every $t$-time, \id2-adversary~$\B$ that makes exactly $q_R$ queries to
  $\RUN$, there exists a $(t + O(q_R))$-time \id1-adversary adversary~$\A$ such
  that

  \begin{equation}
    \Adv{\id2}_\Schnorr(\B) \leq \Adv{\id1}_\Schnorr(\A)
    \,.
  \end{equation}
\end{lemma}
\begin{proof}
  The key observation is that, even though we don't know the secret key~$s$, we
  can still efficiently and perfectly \emph{simulate} executions of the protocol. Consider
  following algorithm:

  \oneCol{0.48}
  {\ga
    \fu $\sim(P)$\\[2pt]
      \li $x \getsr \Z_q$ \#{``Prove''}\\
      \li $h \getsr \Z_q$ \#{``Challenge''}\\
      \li $R \gets g^x \cdot P^{-h}$ \#{``Commit''}\\
      \li \rreturn $(R, h, x)$
  }

  \noindent
  %
  Observe that $\verify(P,R,h,x)=1$ holds for all $(R,h,x)\in[\sim(P)]$:

  \begin{equation}
    g^x = R \cdot P^{h} = (g^x \cdot P^{-h}) \cdot P^h = g^x \,.
  \end{equation}
  %
  That is, algorithm~$\sim$ produces a transcript that looks exactly like the
  genuine article. Moreover, they are \emph{identically distributed}: the real
  protocol samples $r, h \getsr \Z_q$ and lets $R = g^r$ and $x = r + sh$, and
  the simulator samples $x, h \getsr \Z_q$ and lets $R = g^x \cdot P^{-h}$. The
  elements of the transcript have the same mathematical relationship in either
  case.

  Adversary~$\A^{\COMMIT1,\PROVE1}(P)$ works as follows.
  %
  It executes $\B^{\COMMIT1,\PROVE1,\RUN'}(P)$, where $\RUN'$ runs $(R, h,
  x)\getsr\sim(P)$ and returns $(R, h, x)$. It halts whenever~$\B$ halts.
  %
  Then $\A$ wins if~$\B$ does, since~$\B$'s view is identical to the view it
  expects in its game. The claimed bound follows. Note that~$\A$'s runtime is
  $t+O(q_R)$ because simulating each of~$\B$'s $\RUN'$ queries requires $O(1)$
  time.
\end{proof}

It's easy to see that \id2 security implies \id1, since adding the $\RUN$ oracle
makes the adversarial model stronger in general.
%
It follows that \id1 and \id2 security are \emph{equivalent} for~$\Schnorr$!
This is because we can efficiently simulate honest executions of the protocol
without knowing the secret key. This isn't always the case; in general, there
are many commit-then-prove ID schemes that are provably \id1, but notR
\id2.\footnote{\underline{Excercise}. Can you think of any? Hint: any attempt to
simulate the output of~$\RUN$ should fail for such a scheme. Can you think of
how to formalize this property?}\footnote{This property of the $\Schnorr$ is so
important that has a special term: we say that Schnorr's ID protocol is
\emph{honest-verifier zero-knowledge (HVZK)}.  More on this later in the
semester.}

\subsubsection{r\id2 security}
The r\id2 security game in \fig{rid2} is like \id2, except the adversary
is allowed to make~$r$ impersonation attempts in~$r$ concurrent executions of
the protocol. Oracles $\COMMIT{}$ and $\PROVE{}$ take as input an
integer~$i\in[1..r]$, which uniquely identifies the run of the protocol.  Each
run has its own state defined at the beginning of the game (\liref{rid2}{35}).
%
Define the r\id2 advantage of adversary~$\A$ in attacking~$\Sigma$ in~$r$
impersonation attempts as
$\Adv{r\id2}_{\Sigma,r}(\A)=\Prob{\Exp{r\id2}_{\Sigma,r}(\A)=1}$.

We can easily prove that\id2 implies r\id2 \emph{for any commit-then-prove ID
scheme}, though we will lose a factor of~$r$ in the security bound.

\begin{lemma}\label{lemma:id2->rid2}
  Fix integer $r \geq 0$.
  For any commit-then-prove ID scheme~$\Sigma$ (and $\Schnorr$ in particular)
  and every $t$-time r\id2-adversary~$\C$, there exists a $t$-time
  \id2-adversary~$\B$ such that

  \begin{equation}
    \Adv{r\id2}_{\Sigma,r}(\C) \leq r\Adv{\id2}_{\Sigma}(\B) \,.
  \end{equation}
\end{lemma}
\begin{proof}
  We're given an adversary~$\C$ that gets~$r$ tries to impersonate the prover
  and our goal is to construct an adversary~$\B$ that gets only one try.
  %
  The key observation is that we can easily simulate the honest verifier's
  behavior in $r-1$ runs of the protocol and use our own oracles for simulating
  the remaining one. If it happens that~$\C$ wins in the run we used our oracle
  for, then we win, too. Since we have no way of knowing a priori which run is most
  likely to succeed, our best bet is to guess.

  Similarly to the proof of \lem{dl->id1}, we will assume that~$\C$ is properly
  behaved. (That is, it behaves like a cheating prover in each run of the
  protocol.)
  %
  Adversary $\B^{\COMMIT1,\PROVE1,\RUN}(P)$ works as follows. It initializes
  $R_1, \ldots, R_r$, $h_1, \ldots, h_r$, and $x_1, \ldots, x_r$ just as in the
  r\id2 game.
  %
  It samples a random $i^* \getsr [1..r]$ and runs
  $\C^{\COMMIT{}',\PROVE{}',\RUN}(P)$, where $\COMMIT'{}$ and $\PROVE{}'$ are
  defined as follows:

  \begin{itemize}
    \item On input of $(i,R)$, oracle $\COMMIT{}'$ does as follows. If $i\ne
      i^*$, then set $R_i\gets R$, sample $h_i \getsr \Y$ and return $h_i$.
      Otherwise query $h \getsr \COMMIT1(R)$ and return $h$.

    \item On input of $(i,x)$, oracle $\PROVE'{}$ does as follows.
      If $i\ne i^*$, then return $\verify(P,R_i,h_i,x)$. Otherwise query $v
      \getsr \PROVE1(x)$ and return $v$.
  \end{itemize}

  Two conditions must hold in order for~$\B$ to win. First, adversary $\C$ must
  win; and second, it must do so in the $i^*$-th run. Since the random choice
  of~$i^*$ is independent of~$\C$'s random choices, it's (almost) immediate that

  \begin{equation}
    \Prob{\Exp{\id2}_{\Sigma}(\B)=1} \geq 1/r \cdot
    \Prob{\Exp{r\id2}_{\Sigma,r}(\C)=1}
    \,.
  \end{equation}
\end{proof}

By composing Lemmas~\ref{lemma:dl->id1}, \ref{lemma:id1->id2},
and~\ref{lemma:id2->rid2} we conclude that $\Schnorr$ is r\id2 secure if the \dl
problem is hard for~$\G$. In other words, given a suitable choice of~$\G$, it's
apparently infeasible for an adversary to impersonate the prover in Schnorr's ID
protocol even when it is allowed multiple attempts and can eavesdrop on honest
executions.
%
Still, we should ask if this threat model is realistic in practice. What if the
adversary is allowed to \emph{actively} interfere with honest executions of the
protocol? Imagine an adversary who intercepts a commitment in an honest run and
uses it in another run it has initiated; this kind of attack is of practical
interest, but isn't captured in the r\id2 game. Boneh-Franklin (in Sec.~19.8.3)
define security of ID schemes under these kinds of active attacks and show how
to achieve security with respect to them.
%
Nevertheless, r\id2 security is enough for what we aim to prove here.

\subsection{The Fiat-Shamir heuristic}
We can transform any r\id2-secure commit-then-prove ID scheme into a
\ufcma-secure signature scheme via the \emph{Fiat-Shamir heuristic}.
%
Let $\Sigma$ be a commit-then-prove ID scheme. Let $\X$ denote the set of
commitments (i.e., the set of~$R$'s output by $\commit$) and let $\Y$ denote the
set of challenges.
%
(Note that for $\Schnorr$ we have that $\X=\G$ and $\Y=\Z_q$.)
%
Let $H:\X\by\bits^*\to\Y$ be a cryptographic hash function.\footnote{Hash
functions are typically maps from strings to strings; in practice, we need a way
to encode elements of~$\X$ and $\Y$ as strings.}

The idea is very simple. We transform the 3-round, interactive ID protocol into
a \emph{non-interactive} system by replacing $h \getsr \Y$ with $h \gets H(R,
M)$, where~$R$ is the commitment and $M\in\bits^*$.
%
This yields the signature scheme in \fig{fs}.

\begin{figure}[t]
  \threeColsNoDivideUnbalanced{0.30}{0.32}{0.32}
  {\ga
    \fu $\gen(\,)$\\[2pt]
      \li \rreturn $\Sigma.\gen(\,)$
  }
  {
    \fu $\sign(s, M)$\\[2pt]
      \li $(R, r) \getsr \Sigma.\commit(s)$\\
      \li $h \gets H(R,M)$ \#{``Challenge''}\\
      \li $x \getsr \Sigma.\prove(s, r, h)$\\
      \li \rreturn $(R, x)$
  }
  {
    \fu $\verify(P, M, (R, x))$\\[2pt]
      \li $h \gets H(R, M)$\\
      \li \rreturn $\Sigma.\verify(P, R, h, x)$
  }
  \caption{Signature scheme $\FiatShamir[\Sigma,H]=(\gen,\sign,\verify)$ constructed from
  commit-then-prove ID scheme~$\Sigma$ with commitment set~$\X$ and challenge
  set~$\Y$, and hash function~$H:\X\by\bits^*\to\Y$.}
  \vspace{6pt}
  \hrule
  \label{fig:fs}
\end{figure}

In order to reduce the r\id2 security of $\Sigma$ to the \ufcma security of
$\FiatShamir[\Sigma,H]$, we need that computing the signature in the \ufcma game
``behaves'' like running the ID protocol in the r\id2 game.
%
In particular, we need that sampling from the challenge set in the context of
the protocol is to ``look like'' running~$H$ in the context of computing
signatures.
%
To accomplish this, we will model~$H$ as a \emph{random oracle} in the security
analysis.
%
When we model~$H$ as a random oracle in a game, we think of~$H$ as an oracle
that for each unique input $(R,M) \in \X\by\bits^*$, samples $h\getsr\Y$ and
returns it. We can think of populating an arbitrarily large table~$\pi$ as
follows. On input of~$(R,M)$, oracle~$H$ first checks if~$\pi[R,M]$ is defined.
If it is, then it returns $\pi[R,M]$; otherwise it samples $h \getsr \Y$, sets
$\pi[R,M]\gets h$, and returns~$h$.
%
We replace each invocation of~$H$ in the scheme with a call to the random oracle
for~$H$, and we give each the adversary access to the random oracle. That way
the adversary can use information it learns about the random oracle in its
attack on the scheme.

\begin{lemma}\label{lemma:rid2->ufcma}
  Let $H:\G\by\bits^*\to\Z_q$ be a function and let  $\SSchnorr =
  \FiatShamir[\Schnorr,H]$.
  %
  When~$H$ is modeled as a random oracle it holds that for every $t$-time,
  \ufcma-adversary~$\F$ making $r_S$, $r_V$, and $r_H$ queries to $\SIGNO$,
  $\VERIFYO$, and $H$ respectively, there exists a $(t+O(\hat{r}))$-time
  r\id2-adversary~$\C$ making~$r_S$ queries to $\RUN$ such that

  \begin{equation}
    \Adv{\ufcma}_{\SSchnorr}(\F) \leq
      2\hat{r}r_S/q
      + 2\Adv{r\id2}_{\Schnorr,r_V+r_H}(\C)
    \,,
  \end{equation}
  where $\hat{r}=r_S + r_V + r_H$.
\end{lemma}
\noindent
The main idea of the proof is that~$\C$ will simulate~$\F$'s random oracle
queries itself.  Whenever~$\F$ asks a \emph{fresh} $(R,M)$ of~$H$ it initializes
an impersonation attempt in its own game. Suppose that $(R,M)$ is the $i$-th
query to~$H$ made by~$\F$. Treating~$R$ as a commitment, we run
$h\getsr\COMMIT{}(i,R)$, store~$h$ in a table~$\pi$ by setting $\pi[R,M]\gets
h$, and return~$h$.  Adversary~$\C$'s game will sample a random~$h\in\Y$ and
return it, so this is the same as running~$\F$ with a true random oracle
for~$H$.  (If the input $(R,M)$ is not fresh, then we just look up $h \gets
\pi[R,M]$ and return~$h$.)

We \emph{finalize} impersonation attempts when responding to~$\F$'s forgery
attempts. When~$\F$ asks $(M,(R,x))$ of~$\VERIFYO$, if $(R,M)$ corresponds to a
random oracle query used to initialize the $i$-th impersonation attempt, then we
finish the attempt by querying $\COMMIT{}(i,x)$. Since $\pi[R,M]=h$, it holds
that $(M, (R,x))$ is a successful forgery \emph{if and only if} $(R,h,x)$ is a
valid transcript.

The only wrinkle is that we have to answer~$\F$'s signing queries. On input of
$M$ to~$\SIGNO$, we run $(R, h, x)\getsr\RUN(\,)$. If $\pi[R,M]$, is not yet
defined, then we \emph{program} it by setting $\pi[R,M]\gets h$ and return
$(R,x)$ as the signature.
%
We're screwed if $\pi[R,M]$ happens to have already been defined; if we
overwrite this value, then~$\F$ will end up with an inconsistent view, and we
don't get any advantage from using it.
%
Luckily, this ``bad'' event occurs with very low probability.

\begin{proof}[Proof of \lem{rid2->ufcma}]
  We make two assumptions, both without loss of generality: (1) we assume
  that~$\F$ never asks~$(M, (R,x))$ of~$\VERIFYO$ after it gets~$(R,x)$ in
  response to a query of~$M$ to $\SIGNO$; and (2) we assume that if~$\VERIFYO$
  ever returns~$1$ (which indicates a successful forgery), then $\F$ immediately
  halts and outputs~$1$.
  %
  Adversary~$\C^{\COMMIT{},\PROVE{},\RUN}(P)$ works as follows. It simulates
  random oracle queries (by~$\A$ or $\SSchnorr$) by lazy-evaluating
  a table~$\pi$. It also maintains another table~$s$, an integer $i\gets1$, and a
  flag~$\bad\gets0$ for bookkeeping.
  %
  Flip a coin~$b\getsr\bits$ and run $\F^{\SIGNO',\VERIFYO',\RO'}(P)$, where
  $\SIGNO'$, $\VERIFYO'$, and $\RO'$ are defined as follows:
  \begin{itemize}
    \item On input of~$M$, oracle~$\SIGNO'$ does as follows.  Run $(R, h, x)
      \getsr \RUN(\,)$. If $\pi[R,M]$ is defined, then set $\bad\gets1$ and
      \rword{halt}. Otherwise, let $\pi[R,M]\gets h$ and \rreturn $(R, x)$.

    \item On input of $(M, (R,x))$, oracle~$\VERIFYO'$ does as follows. If $b=0$
      then \rreturn $0$. Otherwise do as follows. If $s[R,M]=j$ is defined, then
      finalize the $j$-th impersonation attempt by running $v \getsr
      \PROVE{}(j,x)$ and \rreturn $v$. Otherwise, run
      $\pi[R,M]\getsr\COMMIT{}(i,R)$; $v \getsr \PROVE{}(i,x)$; and $i \gets i +
      1$. Finally, \rreturn $v$.
      %
      (Note that if $s[R,M]$ is undefined, then $\pi[R,M]$ is undefined
      by assumption (1).)

    \item On input of $(R, M)$, oracle~$\RO'$ does as follows.
      If $\pi[R,M]$ is undefined, then initialize the $i$-th impersonation attempt
      by running $\pi[R,M]\getsr\COMMIT{}(i,R)$; $s[R,M]\gets i$; and $i\gets i
      + 1$. Finally, \rreturn $\pi[R,M]$.
  \end{itemize}

  Observe that~$\C$ gives up (\rword{halts}) and sets a flag, $\bad$, if the
  simulation is bound to fail. Since the simulation is perfect until~$\bad$ gets
  set, we're primarily interested in the probability of this happening.
  %
  Let
  \[
    W \bydef \Exp{r\id2}_{\Schnorr,r_V+r_H}(\C) = 1
  \]
  %
  denote the event that~$\C$ wins, and let
  %
  \[
    B \bydef \Exp{r\id2}_{\SSchnorr,r_V+r_H}(\C)\sets \bad
  \]
  %
  denote the event that~$\C$ sets~$\bad$ during the course of its game. Let
  $p_\bad = \Prob{B}$.
  %
  Taking the total probability of~$W$ conditioned on the event~$B$, we have that
  %
  \begin{eqnarray}
    \Adv{r\id2}_{\Schnorr,r_V+r_H}(\C) &=&
      \Prob{W | B}\Prob{B} + \Prob{W | \bnot B}\Prob{\bnot B} \\
    &=&
      p_\bad \Prob{W | B} + (1-p_\bad) \Prob{W | \bnot B} \\
    &\geq&
      \Prob{W | \bnot B} - p_\bad \Prob{W | \bnot B} \\
    &=&
      \Prob{W | \bnot B} - p_\bad (1 - \Prob{\bnot W | \bnot B}) \\
    &\geq&
      \Prob{W | \bnot B} - p_\bad\,.
  \end{eqnarray}
  %
  Now, if~$B$ does not occur, then~$\C$ wins if~$\F$ successfully forges.
  Let
  $
     V \bydef \Exp{\ufcma}_{\SSchnorr}(\F)=1
  $.
  By assumption~(2)
  %
  \begin{eqnarray}
    \Prob{V} &=&
      1/2 \cdot \Prob{V \given b=1} +
      1/2 \cdot \Prob{V \given b=0} \\
    &\leq&
      \Prob{W | \bnot B} + 1/2 \,,
  \end{eqnarray}
  %
  where the first line follows from conditioning on the value of~$b$ in the
  \ufcma experiment.
  Substituting and rearranging,
  %
  \begin{eqnarray}
    \Adv{r\id2}_{\Schnorr,r_V+r_H}(\C) &\geq&
      \Prob{V} - 1/2 - p_\bad \\
    2\Adv{r\id2}_{\Schnorr,r_V+r_H}(\C) &\geq&
      2\Prob{V} - 1 - 2p_\bad \\
    2p_\bad + 2\Adv{r\id2}_{\Schnorr,r_V+r_H}(\C) &\geq&
      \Adv{\ufcma}_{\SSchnorr}(\F) \,.
  \end{eqnarray}
  %
  All that remains is to find $p_\bad$. The game sets~$\bad$ if, on a signing
  query for message~$M$, it happens that $\pi[R,M]$ is defined, where $(R,h,x)$
  is the transcript output by~$\RUN$. This is at most the probability that~$R$
  was used as a commitment in some prior query. Well, $\RUN$ chooses~$R$
  according to $\Schnorr.\commit$, so~$R$ is computed by choosing $r\getsr\Z_q$
  and setting $R\gets g^r$. Hence, the probability that any prior query
  collides with~$R$ is $1/q$. At any given moment in the game, there are at most
  $\hat{r} = r_S + r_V + r_H$ such points, because each of~$\F$'s queries sets
  at most one point in~$\pi$.  Since~$\F$ makes $r_S$ signing queries, it
  follows that $p_\bad \leq \hat{r}r_S /q$.
\end{proof}

\section{Putting it all together}

Given a \ufcma-adversary~$\F$, \lem{rid2->ufcma} gives a recipe for building an
r\id2-adversary~$\C$ that gets similar advantage (at least, for reasonable
$r_S$, $r_V$, and $r_H$) when~$H$ is modeled as a random oracle;
%
given an r\id2-adversary~$\C$, \lem{id2->rid2} gives a recipe for building an
\id2-adversary~$\B$ that gets similar similar advantage (at least, for
reasonable~$r_V + r_H$);
%
given an \id2-adversary~$\B$, \lem{id1->id2} gives us a recipe for building an
\id1-adversary~$\A$ that gets the same advantage.
%
and finally, given an \id1-adversary~$\A$, \lem{dl->id1} gives us a recipe for
breaking the \dl problem for~$\G$.
%
Putting this all together:

\begin{theorem}
  Let $H:\G\by\bits^*\to\Z_q$ be a function and let $\SSchnorr =
  \FiatShamir[\Schnorr,H]$.
  %
  When~$H$ is modeled as a random oracle, it holds that for every $t$-time,
  \ufcma-adversary~$\F$ making $r_S$, $r_V$, and $r_H$ queries to $\SIGNO$,
  $\VERIFYO$, and $H$ respectively, there exists a $O(t+\hat{r})$-time
  \dl-adversary~$\I$ such that

  \begin{eqnarray}
    \Adv{\ufcma}_{\SSchnorr}(\F) &\leq&
      2\hat{r}r_S/q
      + 2(r_V+r_H)\left[1/q + \sqrt{\Adv{\dl}_{\G}(\I)}\,\right] \\
    &\leq&
      4\hat{r}r_S/q
       + 2(r_V+r_H)\sqrt{\Adv{\dl}_{\G}(\I)}
    \;,
  \end{eqnarray}
  where $\hat{r}=r_S + r_V + r_H$.
\end{theorem}

\noindent
That's all folks!

\end{document}
